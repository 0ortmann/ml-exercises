\section{Test \& Training Data Evaluation}

The logarithmic scaling of the target variable \texttt{SalePrice} narrowed the range of values to a much smaller interval. Printing the min/max values of the log-scaled \texttt{SalePrice} gives us $min~10.46027$ and $max~13.53447$. This keeps our prediction errors below 1 and thus allows us to use mean squared error functions.

For testing our predictions we decided to use k-fold cross validation, provided by the \texttt{sklearn.model\_selection} package. We use data shuffling and seed the prng accordingly. For convenient use, we wrote a helper method that wraps the sklearn \texttt{cross\_val\_score} function (it is called \texttt{cross\_val(model)} in our code). The function performs a 5-fold cross validation and returns a score.

We wrote another helper method to print the mean squared error, given a prediction result and a ground truth. This is helpful to detect if a regressor is overfitting.